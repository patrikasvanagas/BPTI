{"cells":[{"cell_type":"code","execution_count":null,"id":"5557e96b","metadata":{"id":"5557e96b"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","import sys\n","import os\n","import cv2\n","from PIL import Image\n","from tqdm import tqdm\n","from random import randint\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import math\n","import glob\n","torch.cuda.empty_cache()\n","\n","weights_path = 'C:/Users/vanag/Desktop/classification_model-3.pkl'\n","classifier_path = 'C:/Users/vanag/Desktop'\n","\n","annotations_dir = 'C:/Users/vanag/Desktop/BPTI/datasets/drone-tracking-datasets/annotations_dataset2.json'\n","files_dir = 'C:/Users/vanag/Desktop/BPTI/datasets/drone-tracking-datasets/dataset2'\n","\n","batch_size = 64\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","sys.path.append(classifier_path)\n","import zoomed_classifier as classifier\n","model = classifier.create_classification_model(weights_path, device)"]},{"cell_type":"code","execution_count":null,"id":"9dbead62","metadata":{"id":"9dbead62"},"outputs":[],"source":["def get_square_bboxes(bboxes):\n","    xmin, ymin, xmax, ymax = bboxes[0], bboxes[1], bboxes[2], bboxes[3]\n","\n","    if (xmax - xmin) > (ymax - ymin):\n","      a, b = ymax, ymin\n","      ymax, ymin = (a + b) / 2 + (xmax - xmin) / 2, (a + b) / 2 - (xmax - xmin) / 2\n","\n","    elif (ymax - ymin) > (xmax - xmin):\n","      a, b = xmax, xmin\n","      xmax, xmin = (a + b) / 2 + (ymax - ymin) / 2, (a + b) / 2 - (ymax - ymin) / 2\n","\n","    if isinstance(xmax, int) == 0: xmax = int(math.ceil(xmax))\n","    if isinstance(xmin, int) == 0: xmin = int(math.ceil(xmin))\n","    if isinstance(ymax, int) == 0: ymax = int(math.ceil(ymax))\n","    if isinstance(ymin, int) == 0: ymin = int(math.ceil(ymin)) \n","\n","    return xmin, ymin, xmax, ymax"]},{"cell_type":"code","execution_count":null,"id":"3aa527cc","metadata":{"id":"3aa527cc","outputId":"71fa42ee-f14d-42cc-99b3-1efdd2fb343a"},"outputs":[{"name":"stderr","output_type":"stream","text":["  5%|â–Œ         | 1143/22146 [02:09<20:54, 16.74it/s] "]}],"source":["df = pd.read_json(annotations_dir)\n","files = os.listdir(files_dir)\n","files.sort\n","\n","fn_dir = files_dir + '_fn'\n","fp_dir = files_dir + '_fp'\n","\n","\n","# comment for only fp detection:\n","neg_img_transform = transforms.Compose([                                \n","    transforms.Resize((128)),\n","    transforms.ToTensor()\n","])\n","os.makedirs(fn_dir, exist_ok = True)\n","for f in os.listdir(fn_dir):\n","    os.remove(os.path.join(fn_dir, f))\n","\n","   \n","# comment for only fn detection:\n","os.makedirs(fp_dir, exist_ok=True)\n","for f in os.listdir(fp_dir):\n","    os.remove(os.path.join(fp_dir, f))\n","   \n","\n","false_negatives = []\n","false_positives = []\n","\n","nr_of_crops = 3\n","\n","empty_imgs = 0\n","non_empty_imgs = 0\n","\n","for i, imgdir in enumerate(tqdm(files)):\n"," title = files[i]    \n","#  title = \"C:/Users/justa/Desktop/Drone/Anti-UAV CVPR 2020/img_ir/\" + files [i]\n"," try:\n","    bboxes = get_square_bboxes(df[title]['bboxes'][0])\n","    fulldir = os.path.join(files_dir, imgdir)\n","    img = Image.open(fulldir)\n","    img = img.crop(bboxes)\n","    non_empty_imgs += 1\n","   \n","    # comment for only fp detection:\n","    if len(img.getbands()) in [1, 4]: img = img.convert('RGB')\n","    trans_img = neg_img_transform(img)\n","    if not classifier.classify_image(trans_img, model, device):\n","      save_image(trans_img, fn_dir+'/%d.jpg'% i)\n","      false_negatives.append(trans_img)\n","       \n","       \n"," except:\n","    fulldir = os.path.join(files_dir, imgdir)\n","    img = Image.open(fulldir)\n","    empty_imgs += 1\n","   \n","    # comment for only fn detection:\n","    if len(img.getbands()) in [1, 4]: img = img.convert('RGB')\n","    for x in range(nr_of_crops):\n","      pos_img_transform = transforms.Compose([\n","        transforms.RandomCrop(randint(32,256)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.Lambda(lambda crop: crop if crop.size[0] > 128 else transforms.Resize((128,128))(crop)),\n","        transforms.ToTensor()\n","      ])\n","      trans_img = pos_img_transform(img)\n","      if classifier.classify_image(trans_img, model, device):\n","          save_image(trans_img, fp_dir+'/%d.jpg'% i)\n","          false_positives.append(trans_img)\n","   \n","nr_results = len(files)\n","\n","# comment for only fp detection\n","fnl = len(false_negatives)\n","print(fnl, \" false negatives, accuracy = \" + str(100*(1-fnl/(nr_results - empty_imgs)))+\"%\")\n","a = open(fn_dir + \"/0_accuracy.txt\", \"w+\")\n","a.write(str(fnl) + \" false negatives, accuracy = \" + str(100*(1-fnl/(nr_results - empty_imgs)))+\"%\\n\")\n","a.close()\n","\n","\n","# comment for only fn detection\n","fpl = len(false_positives)\n","print(fpl, \" false positives, accuracy = \" + str(100*(1-fpl/(nr_of_crops*(nr_results - non_empty_imgs))))+\"%\")\n","b = open(fp_dir + \"/0_accuracy.txt\", \"w+\")\n","b.write(str(fpl) + \" false positives, accuracy = \" + str(100*(1-fpl/(nr_of_crops*(nr_results - non_empty_imgs))))+\"%\\n\")\n","b.close()\n","\n","len(files) == empty_imgs + non_empty_imgs"]},{"cell_type":"code","execution_count":null,"id":"56f8b2f1","metadata":{"id":"56f8b2f1"},"outputs":[],"source":["# f = plt.figure(figsize=(8, 6))\n","# for j in range(6):\n","#     plt.subplot(2, 3, j+1)\n","#     plt.tight_layout()\n","#     plt.imshow(np.transpose(false_negatives[randint(0, fnl-1)], (1, 2, 0)))\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"id":"160e3a3e","metadata":{"id":"160e3a3e"},"outputs":[],"source":["# false negatives\n","\n","annotations_dir = 'C:/Users/pv/Desktop/BPTI/datasets/Anti-UAV CVPR 2020/annotations_IR.json'\n","files_dir = 'C:/Users/pv/Desktop/BPTI/datasets/Anti-UAV CVPR 2020/img_ir'\n","\n","img_transform = transforms.Compose([                                \n","    transforms.Resize((128)),\n","    transforms.ToTensor()\n","])\n","\n","fn_dir = files_dir + '_fn'\n","\n","os.makedirs(fn_dir, exist_ok = True)\n","\n","for f in os.listdir(fn_dir):\n","    os.remove(os.path.join(fn_dir, f))\n","    \n","df = pd.read_json(annotations_dir)\n","files = os.listdir(files_dir)\n","files.sort\n","\n","false_negatives = []\n","nr_of_crops = 1\n","\n","empty_imgs = 0\n","imgs_without_annotation = []\n","\n","for i, imgdir in enumerate(tqdm(files)):\n"," try:\n","     title = \"C:/Users/justa/Desktop/Drone/Anti-UAV CVPR 2020/img_ir/\" + files[i]\n","     if title in df:\n","        if df[title]['bboxes'] not in [[None,None,None,None],None,[],float('nan'),[0,0,0,0]]:\n","          bboxes = df[title]['bboxes'][0]\n","          fulldir = os.path.join(files_dir, imgdir)\n","          img = Image.open(fulldir)\n","          img = img.crop(get_square_bboxes(bboxes))\n","          if len(img.getbands()) in [1, 4]: img = img.convert('RGB')\n","          trans_img = img_transform(img)\n","          if not classifier.classify_image(trans_img, model, device):\n","              save_image(trans_img, fn_dir+'/%d.jpg'% i)\n","              false_negatives.append(trans_img)\n","        else:\n","            empty_imgs +=1\n","     else:\n","        imgs_without_annotation.append(files[i])\n","        pass\n"," except:\n","     print(files[i])\n","     imgs_without_annotation.append(files[i])\n","     pass \n","\n","nr_results = len(files) - empty_imgs - len(imgs_without_annotation)\n","fnl = len(false_negatives)\n","print(fnl, \" false negatives, accuracy = \" + str(100*(1-fnl/(nr_of_crops*nr_results)))+\"%\")\n","\n","f = plt.figure(figsize=(8, 6))\n","for j in range(6):\n","    plt.subplot(2, 3, j+1)\n","    plt.tight_layout()\n","    plt.imshow(np.transpose(false_negatives[randint(0, fnl-1)], (1, 2, 0)))\n","plt.show()\n","\n","t = open(fn_dir + \"/0_accuracy.txt\", \"w+\")\n","t.write(str(fnl) + \" false negatives, accuracy = \" + str(100*(1-fnl/(nr_of_crops*nr_results)))+\"%\\n\")\n","t.write(str('\\nimgs without annotations:\\n'))\n","for i in range(len(imgs_without_annotation)):\n","    t.write(str(imgs_without_annotation[i]) + '\\n')\n","t.close()\n","\n","print(str(empty_imgs) + ' empty imgs')\n","print(str(len(imgs_without_annotation)) + ' imgs without annotations')"]},{"cell_type":"code","execution_count":null,"id":"7f5c8ff1","metadata":{"id":"7f5c8ff1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"da62aab5","metadata":{"id":"da62aab5"},"outputs":[],"source":["# false positives\n","annotations_dir = 'C:/Users/pv/Desktop/BPTI/datasets/Anti-UAV CVPR 2020/annotations_IR.json'\n","files_dir = 'C:/Users/pv/Desktop/BPTI/datasets/Anti-UAV CVPR 2020/img_ir'\n","\n","fp_dir = files_dir + '_fp'\n","os.makedirs(fp_dir, exist_ok=True)\n","\n","for f in os.listdir(fp_dir):\n","    os.remove(os.path.join(fp_dir, f))\n","\n","df = pd.read_json(annotations_dir)\n","files = os.listdir(files_dir)\n","files.sort\n","\n","false_positives = []\n","nr_of_crops = 7\n","\n","non_empty_imgs = 0\n","imgs_without_annotation = []\n","for i, imgdir in enumerate(tqdm(files)):\n","  if files[i] in df:\n","    if df[files[i]]['bboxes'] in [[None, None, None, None], [None]]:\n","      fulldir = os.path.join(files_dir, imgdir)\n","      img = Image.open(fulldir)\n","      if len(img.getbands()) in [1, 4]: img = img.convert('RGB')\n","      for x in range(nr_of_crops):\n","          img_transform = transforms.Compose([\n","            transforms.RandomCrop(randint(32,256)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.Lambda(lambda crop: crop if crop.size[0] > 128 else transforms.Resize((128,128))(crop)),\n","            transforms.ToTensor()\n","          ])\n","          trans_img = img_transform(img)\n","          if classifier.classify_image(trans_img, model, device):\n","              save_image(trans_img, fp_dir+'/%d.jpg'% i)\n","              false_positives.append(trans_img)\n","    else:\n","        non_empty_imgs += 1\n"," else:\n","    imgs_without_annotation.append(files[i])\n","    fulldir = os.path.join(files_dir, imgdir)\n","    img = Image.open(fulldir)\n","    if len(img.getbands()) in [1, 4]: img = img.convert('RGB')\n","    for x in range(nr_of_crops):\n","      img_transform = transforms.Compose([\n","        transforms.RandomCrop(randint(32,256)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.Lambda(lambda crop: crop if crop.size[0] > 128 else transforms.Resize((128,128))(crop)),\n","        transforms.ToTensor()\n","      ])\n","      trans_img = img_transform(img)\n","      if classifier.classify_image(trans_img, model, device):\n","          save_image(trans_img, fp_dir+'/%d.jpg'% i)\n","          false_positives.append(trans_img)\n","\n","nr_results = len(files) - non_empty_imgs - len(imgs_without_annotation)\n","fpl = len(false_positives)\n","print(fpl, \" false positives, accuracy = \" + str(100*(1-fpl/(nr_of_crops*nr_results)))+\"%\")\n","\n","f = plt.figure(figsize=(8, 6))\n","for i in range(6):\n","    plt.subplot(2, 3, i+1)\n","    plt.tight_layout()\n","    plt.imshow(np.transpose(false_positives[randint(0, fpl-1)], (1, 2, 0)))\n","plt.show()\n","\n","t = open(fp_dir + \"/0_accuracy.txt\", \"w+\")\n","t.write(str(fpl) + \" false positives, accuracy = \" + str(100*(1-fpl/(nr_of_crops*nr_results)))+\"%\\n\")\n","t.write(str('\\nimgs without annotations:\\n'))\n","for i in range(len(imgs_without_annotation)):\n","    t.write(str(imgs_without_annotation[i]) + '\\n')\n","t.close()\n","\n","print(str(non_empty_imgs) + 'non-empty imgs')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}