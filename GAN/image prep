{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image prep","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yVeYK9umQqy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627895196390,"user_tz":480,"elapsed":24777,"user":{"displayName":"Spaudžiu Knopkę","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixqyBGaT9e8jGV1KwsN0AuUq524hwo6j4DeoPn=s64","userId":"04346171661928948413"}},"outputId":"9014f65c-e17c-4429-fdb1-0222058b0167"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.utils as vutils\n","from torchsummary import summary\n","from tqdm import tqdm\n","import itertools\n","import time\n","import os\n","from os.path import isfile, join\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","from PIL import Image\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import random\n","import math\n","from collections import OrderedDict\n","from google.colab import drive\n","import sys\n","import subprocess\n","import time\n","import os\n","drive.mount('/content/drive')\n","\n","sys.path.append('/content/drive/MyDrive/BPTI_drone_archive/cycle_GAN_git/util/')\n","import our_lib\n","\n","df = pd.read_json(r'/content/drive/MyDrive/BPTI_drone_archive/dataset/annotations.json')\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'); print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KRciiu4WQuwz","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1627895029040,"user_tz":480,"elapsed":302151,"user":{"displayName":"Spaudžiu Knopkę","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixqyBGaT9e8jGV1KwsN0AuUq524hwo6j4DeoPn=s64","userId":"04346171661928948413"}},"outputId":"7f2ae0a7-8cbb-450b-9416-723f4183128f"},"source":["#@title Download\n","branch = 'master' \n","!git clone https://github.com/OPHoperHPO/image-background-remove-tool.git -b $branch\n","%cd /content/image-background-remove-tool\n","!pip install -r requirements.txt\n","!cd ./tools && echo \"all\" | python setup.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'image-background-remove-tool'...\n","remote: Enumerating objects: 1515, done.\u001b[K\n","remote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 1515 (delta 3), reused 1 (delta 0), pack-reused 1499\u001b[K\n","Receiving objects: 100% (1515/1515), 102.09 MiB | 28.53 MiB/s, done.\n","Resolving deltas: 100% (541/541), done.\n","/content/image-background-remove-tool\n","Collecting pywebview==3.2\n","  Downloading pywebview-3.2-py3-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 8.2 MB/s \n","\u001b[?25hCollecting numpy==1.18.2\n","  Downloading numpy-1.18.2-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n","\u001b[K     |████████████████████████████████| 20.2 MB 1.3 MB/s \n","\u001b[?25hCollecting tqdm==4.43.0\n","  Downloading tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.4 MB/s \n","\u001b[?25hCollecting torch==1.5.0\n","  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n","\u001b[K     |████████████████████████████████| 752.0 MB 9.1 kB/s \n","\u001b[?25hCollecting torchvision==0.2.2.post3\n","  Downloading torchvision-0.2.2.post3-py2.py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.5 MB/s \n","\u001b[?25hCollecting opencv_contrib_python==4.2.0.34\n","  Downloading opencv_contrib_python-4.2.0.34-cp37-cp37m-manylinux1_x86_64.whl (34.2 MB)\n","\u001b[K     |████████████████████████████████| 34.2 MB 31 kB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.4.1)\n","Collecting tensorflow==2.2.1\n","  Downloading tensorflow-2.2.1-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n","\u001b[K     |████████████████████████████████| 516.2 MB 32 kB/s \n","\u001b[?25hCollecting gluoncv==0.7.0\n","  Downloading gluoncv-0.7.0-py2.py3-none-any.whl (752 kB)\n","\u001b[K     |████████████████████████████████| 752 kB 59.5 MB/s \n","\u001b[?25hCollecting gdown==3.11.1\n","  Downloading gdown-3.11.1.tar.gz (8.6 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting scikit_image==0.15.0\n","  Downloading scikit_image-0.15.0-cp37-cp37m-manylinux1_x86_64.whl (26.3 MB)\n","\u001b[K     |████████████████████████████████| 26.3 MB 16 kB/s \n","\u001b[?25hRequirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (7.1.2)\n","Collecting mxnet==1.6.0\n","  Downloading mxnet-1.6.0-py2.py3-none-any.whl (68.7 MB)\n","\u001b[K     |████████████████████████████████| 68.7 MB 27 kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0->-r requirements.txt (line 4)) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2.post3->-r requirements.txt (line 5)) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (1.1.2)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 22.7 MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n","  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n","\u001b[K     |████████████████████████████████| 454 kB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (0.36.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (0.12.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (1.12.1)\n","Collecting h5py<2.11.0,>=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 63.4 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (1.34.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (1.6.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.1->-r requirements.txt (line 8)) (1.1.0)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv==0.7.0->-r requirements.txt (line 9)) (3.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv==0.7.0->-r requirements.txt (line 9)) (2.23.0)\n","Collecting portalocker\n","  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.11.1->-r requirements.txt (line 10)) (3.0.12)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 11)) (2.5.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 11)) (1.1.1)\n","Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit_image==0.15.0->-r requirements.txt (line 11)) (2.4.1)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv==0.7.0->-r requirements.txt (line 9)) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv==0.7.0->-r requirements.txt (line 9)) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv==0.7.0->-r requirements.txt (line 9)) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv==0.7.0->-r requirements.txt (line 9)) (0.10.0)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit_image==0.15.0->-r requirements.txt (line 11)) (4.4.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv==0.7.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv==0.7.0->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv==0.7.0->-r requirements.txt (line 9)) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv==0.7.0->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (57.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (1.8.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (1.32.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (3.3.4)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (0.4.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (4.6.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (3.1.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.1->-r requirements.txt (line 8)) (3.5.0)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv==0.7.0->-r requirements.txt (line 9)) (1.7.1)\n","Building wheels for collected packages: gdown\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.11.1-py3-none-any.whl size=9671 sha256=47d71632d6718bdf1eb4102a0422868351a4c5d72ffd1a29fb9b2cf32644740d\n","  Stored in directory: /root/.cache/pip/wheels/ac/0f/65/f8898ba51a103158b41f418d2a37cc928471624397da3af2f4\n","Successfully built gdown\n","Installing collected packages: numpy, tqdm, torch, tensorflow-estimator, tensorboard, portalocker, h5py, graphviz, gast, torchvision, tensorflow, scikit-image, pywebview, opencv-contrib-python, mxnet, gluoncv, gdown\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.5.0\n","    Uninstalling tensorflow-2.5.0:\n","      Successfully uninstalled tensorflow-2.5.0\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.16.2\n","    Uninstalling scikit-image-0.16.2:\n","      Successfully uninstalled scikit-image-0.16.2\n","  Attempting uninstall: opencv-contrib-python\n","    Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 3.6.4\n","    Uninstalling gdown-3.6.4:\n","      Successfully uninstalled gdown-3.6.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.5.0 which is incompatible.\n","kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.18.2 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed gast-0.3.3 gdown-3.11.1 gluoncv-0.7.0 graphviz-0.8.4 h5py-2.10.0 mxnet-1.6.0 numpy-1.18.2 opencv-contrib-python-4.2.0.34 portalocker-2.3.0 pywebview-3.2 scikit-image-0.15.0 tensorboard-2.2.2 tensorflow-2.2.1 tensorflow-estimator-2.2.0 torch-1.5.0 torchvision-0.2.2.post3 tqdm-4.43.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Choose which model you want to install:\n","u2net\n","basnet\n","u2netp\n","xception_model\n","mobile_net_model\n","all\n","Enter model name: Create folders\n","Start download model archives!\n","Downloading...\n","From: https://github.com/OPHoperHPO/image-background-remove-tool/releases/download/3.2/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz\n","To: /content/image-background-remove-tool/models/mobile_net_model/model.tar.gz\n","100% 23.9M/23.9M [00:00<00:00, 52.6MB/s]\n","Downloading...\n","From: https://github.com/OPHoperHPO/image-background-remove-tool/releases/download/3.2/deeplabv3_pascal_train_aug_2018_01_04.tar.gz\n","To: /content/image-background-remove-tool/models/xception_model/model.tar.gz\n","100% 460M/460M [00:11<00:00, 38.7MB/s]\n","Downloading...\n","From: https://github.com/OPHoperHPO/image-background-remove-tool/releases/download/3.2/u2net.pth\n","To: /content/image-background-remove-tool/models/u2net/u2net.pth\n","100% 176M/176M [00:07<00:00, 22.9MB/s]\n","Downloading...\n","From: https://github.com/OPHoperHPO/image-background-remove-tool/releases/download/3.2/u2netp.pth\n","To: /content/image-background-remove-tool/models/u2netp/u2netp.pth\n","100% 4.68M/4.68M [00:00<00:00, 11.0MB/s]\n","Downloading...\n","From: https://github.com/OPHoperHPO/image-background-remove-tool/releases/download/3.2/basnet.pth\n","To: /content/image-background-remove-tool/models/basnet/basnet.pth\n","100% 348M/348M [00:06<00:00, 55.3MB/s]\n","Download finished!\n","Start unpacking\n","Unpacking 1 archive finished!\n","Unpacking 2 archive finished!\n","Setup finished! :)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8bDFgBKdOdu","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1627894720658,"user_tz":480,"elapsed":233,"user":{"displayName":"Spaudžiu Knopkę","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixqyBGaT9e8jGV1KwsN0AuUq524hwo6j4DeoPn=s64","userId":"04346171661928948413"}},"outputId":"ddd7a564-9e47-491e-e68f-5ed54dc1e5be"},"source":["dir = \"/content/drive/MyDrive/BPTI_drone_archive/dataset/blue/\"\n","\n","cut_dir = \"/content/drive/MyDrive/BPTI_drone_archive/dataset/0_cut/\"\n","\n","transparent_dir = \"/content/drive/MyDrive/BPTI_drone_archive/dataset/0_transparent/\"\n","\n","filenames = os.listdir(dir)\n","\n","filenames.sort()\n","\n","cut_names = []\n","transparent_names = []\n","bash_commands = []\n","\n","for i in tqdm(range(len(filenames))):\n","  bboxes = df[filenames[i]][\"bboxes\"][0]\n","  cut_names.append(cut_dir + filenames[i])\n","  transparent_names.append(transparent_dir + filenames[i][0:-3] + \"png\")\n","  filenames[i] = dir + filenames[i]\n","  xmin, ymin, xmax, ymax = our_lib.square_bboxes(bboxes)\n","  img = Image.open(filenames[i])\n","  img = img.crop((xmin, ymin, xmax, ymax))\n","  img.save(cut_names[i])\n","  bash_commands.append(\"python3 main.py -i \" + cut_names[i] + \" -o \" + transparent_names[i] + \" -m $model_name -prep $preprocessing -postp $postprocessing\")\n","  bashCommand = bash_commands[i]\n","  process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n","  output, error = process.communicate()\n","\n","# os.remove cut"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b2fc53c8b851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransparent_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/BPTI_drone_archive/dataset/0_transparent/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","metadata":{"id":"IQw_b03tRMBk"},"source":["#names\n","filenames =  os.listdir(\"/content/drive/MyDrive/BPTI_drone_archive/BlackWhiteDroneData/30_07_obisidian/\")\n","outputs = []\n","outputs_white = []\n","bash_commands = []\n","for i in (range(len(filenames))):\n","  outputs.append(\"/content/drive/MyDrive/BPTI_drone_archive/BlackWhiteDroneData/30_07_obisidian_transparent/\" + filenames[i][0:-3] + \"png\")\n","  # outputs_white.append(\"/content/drive/MyDrive/BPTI_drone_archive/rembg/out_white/\" + filenames[i])\n","  filenames[i] = \"/content/drive/MyDrive/BPTI_drone_archive/BlackWhiteDroneData/30_07_obisidian/\" + filenames[i]\n","  # outputs_white.append(\"/content/drive/MyDrive/BPTI_drone_archive/rembg/out_white/\" + filenames[i])\n","  bash_commands.append(\"python3 main.py -i \" + filenames[i] + \" -o \" + outputs[i] + \" -m $model_name -prep $preprocessing -postp $postprocessing\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XvfsN5xRPTZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627905701072,"user_tz":480,"elapsed":10469499,"user":{"displayName":"Spaudžiu Knopkę","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixqyBGaT9e8jGV1KwsN0AuUq524hwo6j4DeoPn=s64","userId":"04346171661928948413"}},"outputId":"0e8aee0b-d51a-4246-dea6-c9753d8ea659"},"source":["preprocessing = \"bbd-fastrcnn\" #[\"bbd-fastrcnn\", \"bbmd-maskrcnn\", \"None\"] {allow-input: false}\n","model_name = \"u2net\" # [\"u2net\", \"basnet\", \"u2netp\", \"mobile_net_model\", \"xception_model\"] {allow-input: false}\n","postprocessing = \"rtb-bnb\" #[\"rtb-bnb\", \"rtb-bnb2\", \"No\"] {allow-input: false}\n","\n","for i in tqdm(range(len(filenames))):\n","  bashCommand = bash_commands[i]\n","  process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n","  output, error = process.communicate()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 2046/2046 [2:54:28<00:00,  5.12s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5uF5cpuoRYoa","colab":{"base_uri":"https://localhost:8080/","height":229},"executionInfo":{"status":"error","timestamp":1627894702834,"user_tz":480,"elapsed":223,"user":{"displayName":"Spaudžiu Knopkę","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixqyBGaT9e8jGV1KwsN0AuUq524hwo6j4DeoPn=s64","userId":"04346171661928948413"}},"outputId":"9afbf20b-c077-47df-c6e1-1a76bc8cd8ce"},"source":["for i in range(len(filenames)):\n","  print(len(filenames))\n","  print(len(outputs_white))\n","  img = cv2.imread(outputs[i], cv2.IMREAD_UNCHANGED)\n","  trans_mask = img[:,:,2] == 0\n","  # masko pixeliai yra jeigu \n","  # if img[:,:,0].any == 255 and img[:,:,1].any ==255 and img[:,:,2] ==255:\n","  img = cv2.cvtColor(img, cv2.COLOR_RGB2BGRA)\n","  img[trans_mask] = [255, 255, 255, 0]\n","  img[trans_mask] = [255, 255, 255, 255]\n","  img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n","  cv2.imwrite(filenames[i], img)\n","  # cv2.imwrite(outputs_white[i], img)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e7cda99e3dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_white\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_UNCHANGED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtrans_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'filenames' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdTUVTFGQzKP","executionInfo":{"status":"ok","timestamp":1627647699215,"user_tz":-180,"elapsed":841,"user":{"displayName":"Spaudžiu Knopkę","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GixqyBGaT9e8jGV1KwsN0AuUq524hwo6j4DeoPn=s64","userId":"04346171661928948413"}},"outputId":"0f922f90-4c2f-481a-8c65-ff93817e0b4c"},"source":["dir = \"/content/drive/MyDrive/BPTI_drone_archive/dataset/30_07_generatedANDwhite/\"\n","\n","transparent_dir = \"/content/drive/MyDrive/BPTI_drone_archive/dataset/30_07_generatedANDwhite_transparent/\"\n","\n","filenames = os.listdir(dir)\n","\n","filenames.sort()\n","\n","transparent_names = []\n","\n","for i in tqdm(range(len(filenames))):\n","  transparent_names.append(transparent_dir + filenames[i][0:-3] + \"png\")\n","  filenames[i] = dir + filenames[i]\n","  img = cv2.imread(filenames[i])\n","  img_a = cv2.cvtColor(img, cv2.COLOR_RGB2RGBA)\n","  white = np.all(img >= [240, 240, 240], axis=-1)\n","  img_a[white, -1] = 0\n","  cv2.imwrite(transparent_names[i], img_a)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 101/101 [00:00<00:00, 161.97it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"cellView":"form","id":"vKoS53uORc2y"},"source":["#@title Canny\n","# A_paths = []\n","\n","# for files in os.listdir(dir_A):\n","#   A_paths.append(os.path.join(dir_A, files)) \n","\n","# A_paths = sorted(A_paths)\n","\n","# sorted_test = A_paths\n","\n","# a = 255\n","\n","# BLUR = 21\n","# CANNY_THRESH_1 = a\n","# CANNY_THRESH_2 = a / 3\n","# MASK_DILATE_ITER = 10\n","# MASK_ERODE_ITER = 10\n","# MASK_COLOR = (0.0,0.0,1.0) # In BGR format\n","\n","\n","# filename = A_paths[5]\n","# img = cv2.imread(filename)\n","# xmin, ymin, xmax, ymax = our_lib.square_bboxes(df[str(filename.split('/')[7])]['bboxes'][0])  \n","# img = img[ymin:ymax, xmin:xmax]\n","# cv2_imshow(img)\n","\n","# edges = cv2.Canny(img,CANNY_THRESH_1,CANNY_THRESH_2)\n","# cv2_imshow(edges)\n","# edges = cv2.dilate(edges, None)\n","# cv2_imshow(edges)\n","# edges = cv2.erode(edges, None)\n","# cv2_imshow(edges)\n","\n","# #-- Find contours in edges, sort by area ---------------------------------------------\n","# contour_info = []\n","# contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","\n","# for c in contours:\n","#     contour_info.append((\n","#         c,\n","#         cv2.isContourConvex(c),\n","#         cv2.contourArea(c),\n","#     ))\n","# contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)\n","# max_contour = contour_info[0]\n","\n","\n","# mask = np.zeros(edges.shape)\n","# cv2.fillConvexPoly(mask, max_contour[0], (255))\n","\n","\n","# mask = cv2.dilate(mask, None, iterations=MASK_DILATE_ITER)\n","# mask = cv2.erode(mask, None, iterations=MASK_ERODE_ITER)\n","# mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)\n","# mask_stack = np.dstack([mask]*3)  \n","\n","# mask_stack  = mask_stack.astype('float32') / 255.0        \n","# img         = img.astype('float32') / 255.0  \n","\n","# masked = (mask_stack * img) + ((1-mask_stack) * MASK_COLOR) \n","# masked = (masked * 255).astype('uint8')                     \n","\n","# cv2_imshow(masked)\n","\n","# c_red, c_green, c_blue = cv2.split(img)\n","\n","# # img_a = cv2.merge((c_red, c_green, c_blue, mask.astype('float32') / 255.0))\n","# img_a = cv2.merge((c_blue, c_green, c_red,  mask.astype('float32') / 255.0))\n","\n","\n","# plt.imshow(img_a)\n","\n","# # print(img_a.shape)\n","# # print(img_a[:][:][3][0][0][0].shape)\n","# # plt.imshow(np.transpose(img_a[:][:][2], (2, 1, 0)))\n","\n","\n","\n","\n","\n","\n","\n","# def tensor2rgbuint8 (tensor):\n","# \timg = np.transpose(tensor.cpu(),(1,2,0)).cpu().detach().numpy()\n","# \timg -= img.min()\n","# \timg /= img.max()\n","# \timg = img * 255\n","# \timg = img.astype('uint8')\n","# \treturn (img)"],"execution_count":null,"outputs":[]}]}